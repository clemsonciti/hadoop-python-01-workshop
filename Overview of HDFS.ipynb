{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## <center>Introduction to Hadoop Distributed File System (HDFS)</center>\n",
    "### <center> Linh B. Ngo </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> Overview </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- 2002: Doug Cutting and Mike Carafella started a project to build an open-source search engine called Nutch. A component of this project was a web crawler that can crawl and index the Internet.\n",
    "- 2003: Google released a research paper on its in-house data storage system called [Google File System](http://dl.acm.org/citation.cfm?id=945450) (GFS).\n",
    "- 2004: Google released another research paper on the programming approach to process data stored on GFS, called [MapReduce](http://dl.acm.org/citation.cfm?id=1327492)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- 2005: Cutting and Carafelle rebuilt the underlying file management system and processing framework of Nutch based on the architectural design of Google's GFS and MapReduce.\n",
    "- 2006: The adaptations of Google's GFS and MapReduce are converted into a single open source project called Hadoop, which is sponsored by Yahoo and led by Doug Cutting.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- 2007: Yahoo maintains a 1000-node production cluster.\n",
    "- 2008: Hadoop becomes the platform of Yahoo's web index. Hadoop wins record for world fastest system to sort one terabyte of data (209 seconds using a **910-node** cluster). Hadoop becomes a top-level open source project of Apache Foundation. First Hadoop commercial distributor led by a former Google employee, Cloudera, is founded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- 2009: Hadoop sorts one terabyte of data in 62 seconds and one petabyte of data in 16.25 hours using a **3800-node** cluster. Second Hadoop commercial distributor, MapR, is formed.\n",
    "- 2011: Yahoo spins off its own Hadoop comnmercial distributor, Hortonworks.\n",
    "- 2012: Apache Hadoop 1.0 is released."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Corresponding Component Names**\n",
    "- Google File Systems (GFS): Hadoop Distributed File System (HDFS)\n",
    "- Google MapReduce: Hadoop MapReduce\n",
    "- Google BigTable: Apache HBase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Corresponding Component Names**\n",
    "- GFS Master: NameNode\n",
    "- Chunkserver: DataNode\n",
    "- Chunks: Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Apache Hadoop Project**\n",
    "- Hadoop Distributed File System\n",
    "- YARN (Yet Another Resource Negotiator)\n",
    "- Hadoop MapReduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### <center> Hadoop Distributed File Systems </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Design Assumptions and Goals**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Hardware failure is the norm rather than the exception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Streaming data access\n",
    "    - Not for general purpose applications \n",
    "    - For batch processing rather than interactive use \n",
    "    - For high throughput of data access rather than low latency of data access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Large data sets (terabytes in size)\n",
    "    \n",
    "*This is relative. Sometimes files as small as hundreds of megabytes can also take advantage of Hadoop's data and computation parallelism*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Simple coherency model (write once read many)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Moving computation is cheaper than moving data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Portability across heterogeneous hardware and software platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**HDFS Architecture**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"pictures/10/hdfsarchitecture.png\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"pictures/10/hdfsdatanodes.png\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparing File System Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> \n",
    "    <img src=\"pictures/10/HadoopStorageSimplified.jpg\" width=\"900\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> \n",
    "    <img src=\"pictures/10/HDFSBlockView.jpg\" width=\"900\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> Hadoop 2.0: YARN (Yet Another Resource Negotiator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center> \n",
    "    <img src=\"pictures/10/hadoopyarn.png\" width=\"700\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Conceptual Design/Differences**\n",
    "- Pure scheduler: limited to arbitrating available resources in the system\n",
    "- Pluggable scheduler: multiple scheduling algorithms\n",
    "- Job management is handle by ApplicationMaster\n",
    "- Resource Model:\n",
    "    - Resource-name (hostname, rackname)\n",
    "    - Memory (MB)\n",
    "    - CPU (cores)\n",
    "- ResourceRequest:\n",
    "    - resource-name, priority, resource-requirement, number-of-containers\n",
    "    - Container: the resource allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"pictures/10/yarnflow.png\" width=\"700\"/>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
