{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "layout: page\n",
    "title: Introduction to Hadoop\n",
    "subtitle: Understanding HDFS Files and Directories\n",
    "minutes: 10\n",
    "---\n",
    "> ## Learning Objectives {.objectives}\n",
    ">\n",
    "> *   Understand how files and directories in HDFS are viewed\n",
    ">     relative to files and directories in the Linux file systems.\n",
    "\n",
    "More than just a file storage and management system, HDFS provides an\n",
    "infrastructure through which parallel processing of massive amount of data is\n",
    "enabled.\n",
    "\n",
    "<img src=\"fig/HDFSBlockView.png\" \\\n",
    "     alt=\"HDFSBlockView\" \\\n",
    "     style=\"height:500px\">\n",
    "\n",
    "To enable large scale processing of big data, Hadoop takes a straight forward\n",
    "approach in HDFS, which is to simply divide a very large data file into\n",
    "smaller blocks and distribute these blocks across a cluster of computers\n",
    "(the Hadoop cluster). The blocks are replicated to ensure that if any\n",
    "individual computer fails, there are still enough copies of the data on the\n",
    "remaining computers for uninterrupted operations.\n",
    "\n",
    "Checking block status of file **ratings.csv**:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=512m; support was removed in 8.0\n",
      "Connecting to namenode via http://dscim002.palmetto.clemson.edu:50070/fsck?ugi=lngo&files=1&blocks=1&locations=1&path=%2Fuser%2Flngo%2Fintro-to-hadoop\n",
      "FSCK started by lngo (auth:KERBEROS_SSL) from /10.125.8.212 for path /user/lngo/intro-to-hadoop at Fri Jul 22 15:04:10 EDT 2016\n",
      "/user/lngo/intro-to-hadoop <dir>\n",
      "/user/lngo/intro-to-hadoop/gutenberg-shakespeare.txt 5447744 bytes, 1 block(s):  OK\n",
      "0. BP-1143747467-10.125.40.142-1413584797204:blk_1099953286_26224275 len=5447744 repl=2 [DatanodeInfoWithStorage[10.125.8.197:1019,DS-9d2f85fa-af96-41a0-9a7a-362e07fb0721,DISK], DatanodeInfoWithStorage[10.125.8.196:1019,DS-af361ac7-1213-46f8-8147-2c1356a2315e,DISK]]\n",
      "\n",
      "/user/lngo/intro-to-hadoop/ml-10M100K <dir>\n",
      "/user/lngo/intro-to-hadoop/ml-10M100K/README.html 11563 bytes, 1 block(s):  OK\n",
      "0. BP-1143747467-10.125.40.142-1413584797204:blk_1099955769_26226793 len=11563 repl=2 [DatanodeInfoWithStorage[10.125.8.206:1019,DS-acc010e2-e3c6-48ae-88f4-48e48e071dfa,DISK], DatanodeInfoWithStorage[10.125.8.224:1019,DS-bd7d954b-7eb8-47d6-8d4d-172ea3d31c0a,DISK]]\n",
      "\n",
      "/user/lngo/intro-to-hadoop/ml-10M100K/allbut.pl 753 bytes, 1 block(s):  OK\n",
      "0. BP-1143747467-10.125.40.142-1413584797204:blk_1099955770_26226794 len=753 repl=2 [DatanodeInfoWithStorage[10.125.8.200:1019,DS-83adebbd-087a-416f-970b-0ed5df8ac018,DISK], DatanodeInfoWithStorage[10.125.8.236:1019,DS-7e9ddb9d-efb1-4443-85d2-9a5dd70334c6,DISK]]\n",
      "\n",
      "/user/lngo/intro-to-hadoop/ml-10M100K/movies.dat 522197 bytes, 1 block(s):  OK\n",
      "0. BP-1143747467-10.125.40.142-1413584797204:blk_1099955771_26226795 len=522197 repl=2 [DatanodeInfoWithStorage[10.125.8.229:1019,DS-c1bf0fdf-f493-4125-a4fa-01ca9eaac99c,DISK], DatanodeInfoWithStorage[10.125.8.221:1019,DS-b2994f91-79e1-4ddb-827a-44cc6fb1b4de,DISK]]\n",
      "\n",
      "/user/lngo/intro-to-hadoop/ml-10M100K/ratings.dat 265105635 bytes, 2 block(s):  OK\n",
      "0. BP-1143747467-10.125.40.142-1413584797204:blk_1099955772_26226796 len=134217728 repl=2 [DatanodeInfoWithStorage[10.125.8.204:1019,DS-81cf1971-dc09-4cdf-a088-6229c11d0e0c,DISK], DatanodeInfoWithStorage[10.125.8.217:1019,DS-baa9e3c7-02de-46c7-9fd1-3a61246e0188,DISK]]\n",
      "1. BP-1143747467-10.125.40.142-1413584797204:blk_1099955773_26226797 len=130887907 repl=2 [DatanodeInfoWithStorage[10.125.8.222:1019,DS-14e74b1e-3ba4-4998-bd19-664ea49168cc,DISK], DatanodeInfoWithStorage[10.125.8.218:1019,DS-24818377-8e89-4665-9a96-34da8ffab828,DISK]]\n",
      "\n",
      "/user/lngo/intro-to-hadoop/ml-10M100K/split_ratings.sh 1304 bytes, 1 block(s):  OK\n",
      "0. BP-1143747467-10.125.40.142-1413584797204:blk_1099955774_26226798 len=1304 repl=2 [DatanodeInfoWithStorage[10.125.8.222:1019,DS-9ea52fe1-883e-40ee-bc9a-eba6ecbc5277,DISK], DatanodeInfoWithStorage[10.125.8.223:1019,DS-8dbde862-3337-4e48-89c8-a74b36ca9154,DISK]]\n",
      "\n",
      "/user/lngo/intro-to-hadoop/ml-10M100K/tags.dat 3584119 bytes, 1 block(s):  OK\n",
      "0. BP-1143747467-10.125.40.142-1413584797204:blk_1099955775_26226799 len=3584119 repl=2 [DatanodeInfoWithStorage[10.125.8.216:1019,DS-49b8edac-df81-4da7-93ea-061cd9946db1,DISK], DatanodeInfoWithStorage[10.125.8.211:1019,DS-50be616b-aa46-49e2-a578-ea74fbead1e0,DISK]]\n",
      "\n",
      "Status: HEALTHY\n",
      " Total size:\t274673315 B\n",
      " Total dirs:\t2\n",
      " Total files:\t7\n",
      " Total symlinks:\t\t0\n",
      " Total blocks (validated):\t8 (avg. block size 34334164 B)\n",
      " Minimally replicated blocks:\t8 (100.0 %)\n",
      " Over-replicated blocks:\t0 (0.0 %)\n",
      " Under-replicated blocks:\t0 (0.0 %)\n",
      " Mis-replicated blocks:\t\t0 (0.0 %)\n",
      " Default replication factor:\t2\n",
      " Average block replication:\t2.0\n",
      " Corrupt blocks:\t\t0\n",
      " Missing replicas:\t\t0 (0.0 %)\n",
      " Number of data-nodes:\t\t40\n",
      " Number of racks:\t\t1\n",
      "FSCK ended at Fri Jul 22 15:04:10 EDT 2016 in 2 milliseconds\n",
      "\n",
      "\n",
      "The filesystem under path '/user/lngo/intro-to-hadoop' is HEALTHY\n"
     ]
    }
   ],
   "source": [
    "!ssh dsciu001 hdfs fsck /user/lngo/intro-to-hadoop -files -blocks -locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To bring out the nature of data locality in this distributed block-based\n",
    "approach, it is critical to minimize the needs for data transfer between\n",
    "computers storing these data blocks. A programming approach called\n",
    "***mapreduce*** is leveraged by Google to make this happen.\n",
    "\n",
    "\n",
    "> ## mapreduce vs Apache MapReduce {.callout}\n",
    ">\n",
    "> It is important to distinguish between the mapreduce programming\n",
    "> paradigm and the Apache MapReduce implementation. The mapreduce programming\n",
    "> paradigm includes any implementation approach that ***maps*** the same\n",
    "> operation to individual data elements of a data collection, and then\n",
    "> ***reduce*** the resulting data to a final simplified result. For example,\n",
    "> Apache Spark, the highly touted \"MapReduce killer\", utilizes in-memory\n",
    "> operations to implement its mapping and reducing capabilities. Apache\n",
    "> MapReduce is the defult implementation of the mapreduce\n",
    "> paradigm for Hadoop."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda 2.5.0 (Python 3)",
   "language": "python",
   "name": "anaconda_2.5.0_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
