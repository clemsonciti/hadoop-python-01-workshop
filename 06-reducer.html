<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="generator" content="pandoc">
    <title>Introduction to Hadoop</title>
    <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="stylesheet" type="text/css" href="css/bootstrap/bootstrap.css" />
    <link rel="stylesheet" type="text/css" href="css/bootstrap/bootstrap-theme.css" />
    <link rel="stylesheet" type="text/css" href="css/swc.css" />
    <link rel="alternate" type="application/rss+xml" title="Software Carpentry Blog" href="http://software-carpentry.org/feed.xml"/>
    <meta charset="UTF-8" />
    <!-- HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body class="lesson">
    <div class="container card">
      <div class="banner">
        <a href="http://citi.clemson.edu" title="Software Carpentry">
          <img alt="Software Carpentry banner" src="img/paw.gif" width="100px" height="auto" />
        </a>
      </div>
      <article>
      <div class="row">
        <div class="col-md-10 col-md-offset-1">
                    <a href="index.html"><h1 class="title">Introduction to Hadoop</h1></a>
          <h2 class="subtitle">Creating a Reducer</h2>
          <section class="objectives panel panel-warning">
<div class="panel-heading">
<h2><span class="glyphicon glyphicon-certificate"></span>Learning Objectives</h2>
</div>
<div class="panel-body">
<ul>
<li>Create python-based reducer function and test against non-Hadoop input</li>
</ul>
</div>
</section>
<p>Each reducer will process a collection of KEYS, each KEY associated with a set of VALUEs. It should be noted that in a Python-based Hadoop Streaming environment, intermediate data come into each reducer not as a collection of separated KEY/VALUES groups, but still as a single stream of data whose elements are sorted by KEYs. Create a Python file named <strong>reducer01.py</strong> with the following content:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="co">#!/usr/bin/env python</span>
<span class="kw">import</span> sys

<span class="kw">current_movie</span> = None
<span class="kw">current_rating_sum</span> = 0
<span class="kw">current_rating_count</span> = 0

<span class="kw">for</span> <span class="kw">line</span> in sys.stdin:
  <span class="kw">line</span> = line.strip()
  <span class="kw">movie</span>, rating = line.split(<span class="st">&quot;\t&quot;</span>, 1)
  <span class="kw">try</span>:
    <span class="kw">rating</span> = float(rating)
  <span class="kw">except</span> ValueError:
    <span class="kw">continue</span>

  <span class="kw">if</span> <span class="kw">current_movie</span> == movie:
    <span class="kw">current_rating_sum</span> += rating
    <span class="kw">current_rating_count</span> += 1
  <span class="kw">else</span>:
    <span class="kw">if</span> <span class="kw">current_movie</span>:
      <span class="kw">rating_average</span> = current_rating_sum / current_rating_count
      <span class="kw">print</span> (<span class="st">&quot;%s\t%s&quot;</span> % (current_movie, rating_average))
    <span class="kw">current_movie</span> = movie
    <span class="kw">current_rating_sum</span> = rating
    <span class="kw">current_rating_count</span> = 1

<span class="kw">if</span> <span class="kw">current_movie</span> == movie:
  <span class="kw">rating_average</span> = current_rating_sum / current_rating_count
  <span class="kw">print</span> (<span class="st">&quot;%s\t%s&quot;</span> % (current_movie, rating_average))</code></pre>
<p>To test this script on non-Hadoop data, we can run the following command:</p>
<pre class="sourceCode python"><code class="sourceCode python">!ssh dsciu001 hdfs dfs -cat /user/lngo/intro-to-hadoop/ml-10M100K/ratings.dat <span class="dv">2</span>&gt;/dev/null \
    | head -n <span class="dv">10</span> \
    | python /home/lngo/intro-to-hadoop/mapper02.py \
    | sort \
    | python /home/lngo/intro-to-hadoop/reducer01.py</code></pre>
<pre><code>Boomerang (1992)    5.0
Dumb &amp; Dumber (1994)    5.0
Flintstones, The (1994) 5.0
Forrest Gump (1994) 5.0
Jungle Book, The (1994) 5.0
Lion King, The (1994)   5.0
Net, The (1995) 5.0
Outbreak (1995) 5.0
Stargate (1994) 5.0
Star Trek: Generations (1994)   5.0</code></pre>
<p>The <strong>sort</strong> pipe in the middle will sort all the intermediate data coming from the mapper, effectively emulate Hadoop’s shuffle behavior. This test is somewhat meaningless, as it only tells us that there is no error in our reduce code, but it does not tell us whether our reducer works correctly or not. We need to test for the following: 1. Do all instances of all pairs coming from the mapper arrive at the reducer? 2. Are the calculations correct?</p>
<p>In order to do this, typically we would need to set up a smaller sample data set and manually verify the answers to all the above question. Alternatively, we can also leverage Linux’s capabilities to customize our mapping pipeline.</p>
<pre class="sourceCode python"><code class="sourceCode python">!ssh dsciu001 hdfs dfs -cat /user/lngo/intro-to-hadoop/ml-10M100K/ratings.dat <span class="dv">2</span>&gt;/dev/null \
    | head -n <span class="dv">2000</span> | python /home/lngo/intro-to-hadoop/mapper02.py | grep Matrix</code></pre>
<pre><code>Matrix, The (1999)  5.0
Matrix, The (1999)  5.0
Matrix Reloaded, The (2003) 4.0
Matrix Revolutions, The (2003)  4.0
Matrix, The (1999)  5.0
Matrix, The (1999)  1.0</code></pre>
<p>The above adjusted command lists five possible instances of review for <strong>The Matrix</strong>. We also modify the reducer to include the values of <strong>current_rating_sum</strong> and <strong>current_rating_count</strong> in the output report: <sub>~</sub> {.bash} print (“%s%s%s%s” % (current_movie, rating_average, current_rating_sum, current_rating_count)) <sub>~</sub></p>
<p>Testing this output against the reducer, we observe that our reducer’s operations are correct.</p>
<pre class="sourceCode python"><code class="sourceCode python">!ssh dsciu001 hdfs dfs -cat /user/lngo/intro-to-hadoop/ml-10M100K/ratings.dat <span class="dv">2</span>&gt;/dev/null \
    | head -n <span class="dv">2000</span> | python /home/lngo/intro-to-hadoop/mapper02.py \
    | grep Matrix | sort \
    | python /home/lngo/intro-to-hadoop/reducer02.py</code></pre>
<pre><code>Matrix Reloaded, The (2003) 4.0 4.0 1
Matrix Revolutions, The (2003)  4.0 4.0 1
Matrix, The (1999)  4.0 16.0    4</code></pre>
<h2 id="check-your-understanding-map-genres-to-ratings" class="challenge">Check your understanding: Map genres to ratings</h2>
<p>While the reducer code uses variables such as movie and current_movie, in principle, this reducer can take any set of KEY/GROUP OF VALUES and calculate the average value of this KEY. Use this reducer together with <strong>mapGenre.py</strong> to test the finding of rating averages of movie genres.</p>
        </div>
      </div>
      </article>
      <div class="footer">
        <a class="label clemson-orange" href="http://citi.clemson.edu">CITI</a>
        <a class="label clemson-orange" href="https://github.com/clemsoncoe/hpc-workshop">Source</a>
        <a class="label clemson-orange" href="mailto:atrikut@clemson.edu">Contact</a>
        <a class="label clemson-orange" href="LICENSE.html">License</a>
      </div>
    </div>
    <!-- Javascript placed at the end of the document so the pages load faster -->
    <script src="http://software-carpentry.org/v5/js/jquery-1.9.1.min.js"></script>
    <script src="css/bootstrap/bootstrap-js/bootstrap.js"></script>
  </body>
</html>
